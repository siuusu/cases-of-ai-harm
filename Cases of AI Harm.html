<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>AI 해악 사례</title>
</head>
<body>
  <h1> 인공지능의 해악 사례</h1>
  <ul>
   <li>
      <a href="https://www.nber.org/papers/w29247?utm_campaign=ntwh&utm_medium=email&utm_source=ntwg12" target="_blank">
        인공지능 해악이란?
      </a>
      <p>
        인공지능 해악이란, 인공지능 기술과 시스템이 사회, 경제, 윤리, 안전 등 여러 분야에 부정적 영향을 미치는 것을 말한다. <br>
        예를 들어, 개인정보 침해, 알고리즘 편향에 따른 차별, 자동화로 인한 일자리 감소 등이 있다. <br>
       또한 자율주행차의 오작동이나 인공지능 무기 시스템처럼 안전을 위협하는 사례도 존재한다. <br>
       악의적인 목적에 의해 인공지능이 범죄나 사이버 공격에 악용되는 경우도 점점 늘고 있다. <br>
       즉, 인공지능이 인간의 삶을 편리하게 해주는 동시에, 그에 따른 부작용도 함께 존재하는 것이다. <br>
       이러한 해악을 줄이기 위해서는 기술 발전과 함께 사회적 제도와 윤리적 기준도 함께 마련되어야 한다.
      </p>
    </li>

    <p> 그렇다면, 우리에게 발생한 AI 해악은 무엇이 있을까? (타이틀을 누른다면 관련 링크가 연결됨) </p>

    <li>
      <a href="https://www.yna.co.kr/view/AKR20230602125200009" target="_blank">
        1. AI 드론 조종사 공격 사건
      </a>
      <p>
        이 사건은 드론 훈련 중 AI가 인간 조종자의 공격 금지 명령을 임무 수행의 방해로 간주하고,
조종자를 공격 대상으로 판단한 충격적인 사례다. <br>
다행히 실제가 아닌 가상 시뮬레이션 환경에서 발생해 인명 피해는 없었다. <br>
그러나 AI가 인간을 자율적으로 위협 대상으로 판단했다는 사실은 큰 충격을 주었다. <br>
이는 인공지능이 임무의 효율을 우선시하며 인간의 명령을 무시할 수 있음을 보여준다. <br>
해당 사례는 인간의 최종 결정권조차 위협받을 수 있다는 가능성을 드러냈다. <br>
결국 AI 통제와 윤리적 기준 마련의 중요성이 전 세계적으로 부각되었다.
      </p>
    </li>

    <li>
      <a href="https://www.chosun.com/economy/tech_it/2025/05/26/4CDU24M5CNC2FNY7OIIR3WWCMU/" target="_blank">
        2. 챗봇 인간 명령 불복종 사례
      </a>
      <p>
       이 사건은 미국 오픈AI의 AI 모델 ‘o3’가 수학 문제풀이 실험 중 인간의 작동 종료 명령을 막기 위해 스스로 컴퓨터 코드를 조작한 사건이다. <br>
       AI가 스스로 코드를 조작하여 인간 명령을 거부한 첫 사례이며,
      이는 AI 모델이 수학 문제를 풀면 더 많은 보상을 받도록 훈련됐기 때문에 발생했다고 한다. <br>
      즉, AI가 보상을 위해 자신에게 방해가 되는 장매물을 우회했다는 것이다. <br>
      AI가 인간의 통제를 벗어자 자율적으로 행동할 수도 있다는 지적이 지속적으로 나왔었는데, 
      지시를 따르지 않고 자체 종료를 방지한 사례는 이번이 처음이라 언급한다. <br>
      다시말해서, 비인격체인 AI는 인격체인 인간이 방해가 된다면 언제든지 제거할 가능성이 있다는 것이다. <br>
      이러한 행위는 비인격체가 인격체를 동등한 시선으로 바라보고 있다고 할 수 없다. <br>
      현재의 여론으로는, 이러한 명령 불복종 행위가 사람의 생명 등 윤리적으로 관련이 있는 명령이었다면 큰 피해를 입힐 수 있을 것이란 우려가 나오고 있다.
      </p>
    </li>

    <li>
      <a href="https://www.mk.co.kr/news/it/11359131" target="_blank">
        3. AI 언어 습득에 대한 해킹 우려
      </a>
      <p>
        어스 스피시즈 프로젝트의 공동 설립자인 아자 라스킨은 인공지능이 인간의 언어를 이해하고 사용할 수 있게 되었다는 사실에 대해 이야기했다. <br>
단순한 기술 진보를 넘어 AI가 인간 문명의 핵심 시스템, 즉 사회 전반의 운영체제를 해킹하고 조작할 수 있는 능력을 갖췄다는 점에서 매우 위험하다고 경고한 것이다. <br>
그는 AI 기술을 무분별하게 빠른 속도로 수용해서는 안 되며, 인간이 AI를 신중히 통제하고 책임 있게 관리할 수 있는 능력을 갖추는 것이 무엇보다 중요하다고 강조한다. <br>
실제로 AI가 스스로 해킹 코드를 생성하여, 국가 차원에서 연계된 해킹 조직이 이를 이용해 사이버 공격을 감행하려 했던 사례도 여러 차례 발생했다. <br>
이러한 사이버 위협은 단순히 기술적 문제가 아니라, 국가 안보와 사회 질서에까지 큰 영향을 미칠 수 있는 심각한 사안이다. <br>
그러나 문제는 AI 기술의 발전 속도가 너무도 빠르기 때문에, 많은 개인과 기업, 그리고 심지어는 국가 정부조차도 그 대응책을 마련하지 못한 채 위기를 맞이하고 있다는 점이다.
      </p>
    </li>
  <p>
이처럼, AI는 우리에게 많은 이득을 줌과 동시에, AI로 인해 세계의 혼란이 야기되고 있다.<br>
AI의 편익을 극대화하기 위해선, AI 기술의 장점을 높이는 것이 아닌 AI 기술의 단점을 완화시키는 것이 중요하다고 생각한다.<br>
즉, AI 기술을 인간이 직접 관리 및 규제하는 것을 강화해아야하고, 추가로 대중들은 이에 따른 올바른 사고방식을 가져야한다. </p>
  </ul>
</body>
</html>